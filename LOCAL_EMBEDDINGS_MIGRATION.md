# Local Embeddings Migration - Complete

**‚úÖ Implementation complete!** Switched from OpenAI API (1536 dims) to local sentence-transformers (384 dims).

## What Changed

### 1. **Added Local Embedding Model**
- Model: `all-MiniLM-L6-v2` (80MB, 384 dimensions)
- Speed: **50-200ms** vs 1000-3400ms with OpenAI API
- Quality: ~85% of OpenAI (good enough for most use cases)
- Cost: **Free** (no API calls)

### 2. **Files Modified**
- `requirements.txt` - Added sentence-transformers==2.2.2
- `backend/app/rag/local_embedder.py` - NEW: Local embedding class
- `backend/app/config.py` - Added RAG_USE_LOCAL_EMBEDDINGS config
- `backend/app/rag/retriever.py` - Support local + OpenAI embeddings
- `backend/app/rag/document_processor.py` - Support local + OpenAI
- `backend/app/api/documents.py` - Initialize local embedder
- `backend/app/main.py` - Pass local embedder to RAG
- `backend/app/orchestration/turn_controller.py` - Updated enable_rag()
- `backend/.env` - Updated configs

### 3. **Environment Variables Updated**
```bash
# Changed
PINECONE_INDEX_NAME=voice-agent-kb-local  # New index
PINECONE_DIMENSION=384                     # Was 1536
RAG_USE_LOCAL_EMBEDDINGS=true             # NEW
RAG_MIN_SIMILARITY=0.40                   # Raised from 0.25
```

## Setup Instructions

### Step 1: Install Dependencies
```bash
cd backend
pip install -r requirements.txt
```

This will download sentence-transformers and the model (~80MB).

### Step 2: Recreate Pinecone Index
```bash
cd backend
python recreate_pinecone_index.py
```

‚ö†Ô∏è **WARNING:** This deletes the old index! Type `DELETE` to confirm.

The script will:
- Delete `voice-agent-kb` (1536 dims)
- Create `voice-agent-kb-local` (384 dims)
- Wait for index to be ready

### Step 3: Restart Server
```bash
cd backend
python -m uvicorn app.main:app --reload --port 8000
```

You should see:
```
Loading local embedding model: all-MiniLM-L6-v2
‚úÖ Local embedding model loaded (384 dimensions)
```

### Step 4: Re-upload Documents
All previous documents are gone (different index). Re-upload via:
- Frontend: Click "Upload Document"
- API: POST `/api/documents/upload`

## Performance Comparison

| Metric | Before (OpenAI) | After (Local) | Improvement |
|--------|----------------|---------------|-------------|
| Embedding time | 1000-3400ms | **50-200ms** | **10-17x faster** ‚úÖ |
| Cost per query | $0.00002 | **$0.00** | **100% savings** ‚úÖ |
| Network dependency | Required | **None** | **Offline capable** ‚úÖ |
| Quality | 100% | ~85% | Small trade-off |
| Memory usage | 0MB | 200-300MB | Railway handles fine |

## Expected Latency Now

```
T=0ms:      User speech arrives
T=400ms:    RAG starts (speculative, during debounce)
T=500ms:    Silence confirmed
T=650ms:    RAG completes (150ms for embedding + search)
            LLM has context, starts generating
T=1700ms:   First sentence ready
T=2700ms:   First audio chunk
```

**Total latency: ~2700ms** (was 10890ms with slow OpenAI API)

## Verification

Test with query: **"Tell me about the omni dimension document"**

Expected logs:
```
üîç RAG retrieve starting: query='Tell me about the omni dimension...'
üîÑ Step 1: Generating query embedding...
‚úÖ Embedding generated in 120ms          ‚Üê Fast!
üîç Step 2: Searching Pinecone...
üìä Top similarity scores: 0.425, 0.418
‚úÖ RAG retrieve completed in 250ms       ‚Üê Total fast!
‚úÖ RAG: Retrieved 3 relevant chunks
```

## Troubleshooting

### Model fails to load
```
ERROR: Failed to load sentence-transformers model
```
**Fix:** Check internet connection on first run (downloads model)

### Wrong dimensions error
```
ValidationError: PINECONE_DIMENSION must be 384
```
**Fix:** Update `.env` file with new dimension

### No embeddings generated
```
ERROR: No embedding method available
```
**Fix:** Ensure `RAG_USE_LOCAL_EMBEDDINGS=true` in `.env`

### Documents not found
```
Search returned 0 results
```
**Fix:** Re-upload documents (old index was deleted)

## Rollback (if needed)

To revert to OpenAI API:

1. Update `.env`:
   ```bash
   RAG_USE_LOCAL_EMBEDDINGS=false
   PINECONE_INDEX_NAME=voice-agent-kb
   PINECONE_DIMENSION=1536
   ```

2. Recreate 1536-dim index
3. Re-upload documents
4. Restart server

## Next Steps

- ‚úÖ Test RAG with various queries
- ‚úÖ Verify latency improvements
- ‚úÖ Re-upload important documents
- ‚úÖ Monitor memory usage on Railway
- ‚úÖ Consider raising similarity threshold to 0.5-0.6 for better quality

---

**üéâ You now have 10x faster RAG with zero API costs!**
